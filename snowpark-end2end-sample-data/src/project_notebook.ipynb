{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  00-connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ENV CONFIGURATION '''\n",
    "# pip install python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dotenv_path = os.path.join(os.getcwd(), \".env\")  # Replace \".env\" with the actual file path if it's in a different location\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "ACCOUNT = os.environ.get(\"ACCOUNT\", \"default\")\n",
    "USER = os.environ.get(\"USER\", \"default\")\n",
    "PASSWORD = os.environ.get(\"PASSWORD\", \"default\")\n",
    "ROLE = os.environ.get(\"ROLE\", \"default\")\n",
    "DATABASE = os.environ.get(\"DATABASE\", \"default\")\n",
    "WAREHOUSE = os.environ.get(\"WAREHOUSE\", \"default\")\n",
    "# a3491fb2-000f-4d9f-943e-127cfe29c39c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 01 - CREATE USER AND WH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:01:58 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:01:58 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:01:59 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664822094,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:01:59 - INFO - query: [select current_role(), current_database(), current_schema(), current_warehouse()...]\n",
      "01:01:59 - INFO - query execution done\n",
      "01:01:59 - INFO - Number of results in first chunk: 0\n",
      "01:01:59 - INFO - query: [SELECT  *  FROM (select current_role(), current_database(), current_schema(), cu...]\n",
      "01:02:00 - INFO - query execution done\n",
      "01:02:00 - INFO - Number of results in first chunk: 1\n",
      "----------------------------------------------------------------------------------------------\n",
      "|\"CURRENT_ROLE()\"        |\"CURRENT_DATABASE()\"  |\"CURRENT_SCHEMA()\"  |\"CURRENT_WAREHOUSE()\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|DEV_ENT_DW_ENGINEER_FR  |NULL                  |NULL                |NULL                   |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "01:02:00 - INFO - query: [select c_custkey,c_name,c_phone,c_mktsegment from snowflake_sample_data.tpch_sf1...]\n",
      "01:02:00 - INFO - query execution done\n",
      "01:02:00 - INFO - Number of results in first chunk: 0\n",
      "01:02:00 - INFO - query: [SELECT  *  FROM (select c_custkey,c_name,c_phone,c_mktsegment from snowflake_sam...]\n",
      "01:02:00 - INFO - query execution done\n",
      "01:02:00 - INFO - Number of results in first chunk: 5\n",
      "-----------------------------------------------------------------------\n",
      "|\"C_CUSTKEY\"  |\"C_NAME\"            |\"C_PHONE\"        |\"C_MKTSEGMENT\"  |\n",
      "-----------------------------------------------------------------------\n",
      "|60001        |Customer#000060001  |24-678-784-9652  |HOUSEHOLD       |\n",
      "|60002        |Customer#000060002  |25-782-500-8435  |BUILDING        |\n",
      "|60003        |Customer#000060003  |26-859-847-7640  |BUILDING        |\n",
      "|60004        |Customer#000060004  |20-573-674-7999  |AUTOMOBILE      |\n",
      "|60005        |Customer#000060005  |22-741-208-1316  |MACHINERY       |\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# initiate logging at info level\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S')\n",
    "\n",
    "# snowpark session\n",
    "def get_snowpark_session() -> Session:\n",
    "    connection_parameters =  {\n",
    "       \"ACCOUNT\":ACCOUNT,\n",
    "        \"USER\":USER,\n",
    "        \"PASSWORD\":PASSWORD,\n",
    "        \"ROLE\":ROLE,\n",
    "        \"DATABASE\":DATABASE,\n",
    "        \"SCHEMA\":\"ALF_SNOWPARK\",\n",
    "        \"WAREHOUSE\":WAREHOUSE,\n",
    "        \"session_parameters\":{\n",
    "            'QUERY_TAG': 'DevOPS_deployment',\n",
    "            'use_openssl_only': True\n",
    "        }\n",
    "    }\n",
    "    # print(connection_parameters)\n",
    "    # creating snowflake session object\n",
    "    return Session.builder.configs(connection_parameters).create()   \n",
    "\n",
    "def main():\n",
    "    session = get_snowpark_session()\n",
    "    \n",
    "    context_df = session.sql(\"select current_role(), current_database(), current_schema(), current_warehouse()\")\n",
    "    context_df.show(2)\n",
    "\n",
    "    customer_df = session.sql(\"select c_custkey,c_name,c_phone,c_mktsegment from snowflake_sample_data.tpch_sf1.customer limit 10\")\n",
    "    customer_df.show(5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 02 - CREATE SCHEMA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 03 - CREATE INTERNAL STAGE IN SOURCE SCHEMA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.2 Loading Data To Internal Stage Using Snowpark File API\n",
    "Following Snowpark Program is using File API to read the data from local machine and loading into Snowpark Internal Stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aseka\\repos\\snowflake-coding\\snowpark-end2end-sample-data\\dataset\\sales\n",
      "c:\\Users\\aseka\\repos\\snowflake-coding\\snowpark-end2end-sample-data\\dataset\\sales\n",
      "c:\\Users\\aseka\\repos\\snowflake-coding\\snowpark-end2end-sample-data\\dataset\\sales\n",
      "01:02:00 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:00 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:01 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664819094,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:01 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:01 - INFO - query execution done\n",
      "order-20200101.csv  =>  UPLOADED\n",
      "01:02:02 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:02 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:03 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664819098,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:03 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:03 - INFO - query execution done\n",
      "order-20200102.csv  =>  UPLOADED\n",
      "01:02:04 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:04 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:05 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664819102,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:05 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:05 - INFO - query execution done\n",
      "order-20200101.snappy.parquet  =>  UPLOADED\n",
      "01:02:06 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:06 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:07 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664822098,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:07 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:07 - INFO - query execution done\n",
      "order-20200102.snappy.parquet  =>  UPLOADED\n",
      "01:02:08 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:08 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:08 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664819106,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:08 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:09 - INFO - query execution done\n",
      "order-20200101.snappy.parquet  =>  UPLOADED\n",
      "01:02:10 - INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.8, Platform: Windows-10-10.0.22621-SP0\n",
      "01:02:10 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "01:02:11 - INFO - Snowpark Session information: \n",
      "\"version\" : 1.14.0,\n",
      "\"python.version\" : 3.8.8rc1,\n",
      "\"python.connector.version\" : 3.7.1,\n",
      "\"python.connector.session.id\" : 343664822102,\n",
      "\"os.name\" : Windows\n",
      "\n",
      "01:02:11 - INFO - query: [PUT 'file://c:/Users/aseka/repos/snowflake-coding/snowpark-end2end-sample-data/d...]\n",
      "01:02:11 - INFO - query execution done\n",
      "order-20200102.snappy.parquet  =>  UPLOADED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def traverse_directory(directory, file_extension) -> list:\n",
    "\tlocal_file_path = []\n",
    "\tfile_name = [] # list to csv file path \n",
    "\tpartition_dir = []\n",
    "\tprint(directory)\n",
    "\tfor root, dirs, files in os.walk(directory):\n",
    "\t\tfor file in files:\n",
    "\t\t\tif file.endswith(file_extension):\n",
    "\t\t\t\tfile_path = os.path.join(root, file)\n",
    "\t\t\t\tfile_name.append(file)\n",
    "\t\t\t\tpartition_dir.append(root.replace(directory, ''))\n",
    "\t\t\t\tlocal_file_path.append(file_path)\n",
    "\n",
    "\treturn file_name, partition_dir, local_file_path\n",
    "\n",
    "\n",
    "def main():\n",
    "\t# Specify the directory path to traverse\n",
    "\t# Get the current working directory\n",
    "\tcurrent_dir = os.getcwd()\n",
    "\tcurrent_dir = os.path.abspath('..')\n",
    "\t# Specify the path to the \"dataset/sales\" directory\n",
    "\tdirectory_path = os.path.join(current_dir, 'dataset', 'sales')\n",
    "\n",
    "\t# Print the path\n",
    "\t# print(directory_path)\n",
    "\n",
    "\tcsv_file_name, csv_partition_dir , csv_local_file_path= traverse_directory(directory_path,'.csv')\n",
    "\n",
    "\tparquet_file_name, parquet_partition_dir , parquet_local_file_path= traverse_directory(directory_path,'.parquet')\n",
    "\tjson_file_name, json_partition_dir , json_local_file_path= traverse_directory(directory_path,'.json')\n",
    "\tstage_location = \"@DEMO_DB.ALF_SOURCE.MY_INTERNAL_STAGE\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tcsv_index = 0\n",
    "\n",
    "\tfor file_element in csv_file_name:\n",
    "\t\tcsv_partition_dir[csv_index] = csv_partition_dir[csv_index].replace(\"\\\\\" , \"/\")\n",
    "\t\tput_result = (\n",
    "\t\t\tget_snowpark_session().file.put(\n",
    "\t\t\t\tlocal_file_name=csv_local_file_path[csv_index],\n",
    "\t\t\t\tstage_location=rf\"{stage_location+csv_partition_dir[csv_index]}\",\n",
    "\t\t\tauto_compress=True, overwrite=True, parallel=10)\n",
    "\t\t)\n",
    "\t\tprint(file_element,\" => \",put_result[0].status)\n",
    "\t\tcsv_index+=1\n",
    "\n",
    "\tparquet_index = 0\n",
    "\tfor file_element in parquet_file_name:\n",
    "\t\tparquet_partition_dir[parquet_index] = parquet_partition_dir[parquet_index].replace(\"\\\\\" , \"/\")\n",
    "\t\tput_result = ( \n",
    "\t\t\tget_snowpark_session().file.put( \n",
    "\t\t\t\tlocal_file_name=parquet_local_file_path[parquet_index], \n",
    "\t\t\t\tstage_location=rf\"{stage_location+parquet_partition_dir[parquet_index]}\",\n",
    "\t\t\t\tauto_compress=True, overwrite=True, parallel=10)\n",
    "\t\t\t)\n",
    "\t\tprint(file_element,\" => \",put_result[0].status)\n",
    "\t\tparquet_index+=1\n",
    "\n",
    "\n",
    "\tjson_index = 0\n",
    "\tfor file_element in parquet_file_name:\n",
    "\t\tjson_partition_dir[json_index] = json_partition_dir[json_index].replace(\"\\\\\" , \"/\")\n",
    "\t\tput_result = ( \n",
    "\t\t\tget_snowpark_session().file.put( \n",
    "\t\t\t\tjson_local_file_path[json_index], \n",
    "\t\t\t\t# stage_location+\"/\"+json_partition_dir[json_index], \n",
    "\t\t\t\tstage_location=rf\"{stage_location+json_partition_dir[json_index]}\",\n",
    "\t\t\t\tauto_compress=True, overwrite=True, parallel=10)\n",
    "\n",
    "\t\t\t)\n",
    "\t\tprint(file_element,\" => \",put_result[0].status)\n",
    "\t\tjson_index+=1 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 05: FILE FORMATS IN COMMON SCHEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5.1 Select Statements On Internal Stage (CSV, Parquet, JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP - 6: FOREX DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-7.1 Loading Data From Internal Stage to Source Tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Source Table DDL Script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
